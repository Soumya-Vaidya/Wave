{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# To ignore all warnings globally\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that game hurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexuality should not be a group category it m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you do right  if you do not care then fuck them</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man i love reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name  be nowhere near them  he be by the falcon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  admiration  amusement  \\\n",
       "0                                    that game hurt            0          0   \n",
       "1   sexuality should not be a group category it m...           0          0   \n",
       "2   you do right  if you do not care then fuck them            0          0   \n",
       "3                                 man i love reddit            0          0   \n",
       "4   name  be nowhere near them  he be by the falcon            0          0   \n",
       "\n",
       "   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  \\\n",
       "0      0          0         0       0          0          0       0  ...   \n",
       "1      0          0         0       0          0          0       0  ...   \n",
       "2      0          0         0       0          0          0       0  ...   \n",
       "3      0          0         0       0          0          0       0  ...   \n",
       "4      0          0         0       0          0          0       0  ...   \n",
       "\n",
       "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0     0            0         0      0            0       0        0        1   \n",
       "1     0            0         0      0            0       0        0        0   \n",
       "2     0            0         0      0            0       0        0        0   \n",
       "3     1            0         0      0            0       0        0        0   \n",
       "4     0            0         0      0            0       0        0        0   \n",
       "\n",
       "   surprise  neutral  \n",
       "0         0        0  \n",
       "1         0        0  \n",
       "2         0        1  \n",
       "3         0        0  \n",
       "4         0        1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed_data1.csv\")\n",
    "df['text'] = df['text'].fillna('')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract features (text) and labels\n",
    "X_train = train_data['text']\n",
    "X_test = test_data['text']\n",
    "y_train = train_data.iloc[:, 1:]\n",
    "y_test = test_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "# Use oversampling for each label\n",
    "X_resampled, y_resampled = [], []\n",
    "for i in range(y_train.shape[1]):\n",
    "    # Reshape X_train to be 2D\n",
    "    X_res, y_res = ros.fit_resample(np.array(X_train).reshape(-1, 1), y_train.iloc[:, i])\n",
    "    X_resampled.append(X_res)\n",
    "    y_resampled.append(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38      1132\n",
      "           1       0.56      0.37      0.44       621\n",
      "           2       0.46      0.10      0.16       519\n",
      "           3       0.28      0.03      0.06       946\n",
      "           4       0.41      0.05      0.09      1132\n",
      "           5       0.36      0.05      0.09       397\n",
      "           6       0.54      0.05      0.10       500\n",
      "           7       0.53      0.05      0.09       680\n",
      "           8       0.29      0.06      0.10       242\n",
      "           9       0.31      0.03      0.05       574\n",
      "          10       0.41      0.03      0.05       754\n",
      "          11       0.45      0.08      0.13       328\n",
      "          12       0.50      0.06      0.10       158\n",
      "          13       0.51      0.06      0.11       378\n",
      "          14       0.61      0.20      0.31       210\n",
      "          15       0.88      0.76      0.82       816\n",
      "          16       0.00      0.00      0.00        41\n",
      "          17       0.42      0.11      0.17       514\n",
      "          18       0.62      0.54      0.58       517\n",
      "          19       0.27      0.03      0.05       111\n",
      "          20       0.54      0.21      0.30       570\n",
      "          21       0.40      0.04      0.07        99\n",
      "          22       0.49      0.03      0.05       615\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.42      0.16      0.23       180\n",
      "          25       0.53      0.18      0.27       418\n",
      "          26       0.45      0.12      0.19       368\n",
      "\n",
      "   micro avg       0.59      0.17      0.26     12920\n",
      "   macro avg       0.44      0.14      0.18     12920\n",
      "weighted avg       0.49      0.17      0.22     12920\n",
      " samples avg       0.14      0.12      0.13     12920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with CountVectorizer and Logistic Regression\n",
    "text_clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', OneVsRestClassifier(LogisticRegression(max_iter=100)))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Parameters: {'classifier__estimator__C': 1, 'vectorizer__max_features': 1000, 'vectorizer__ngram_range': (1, 2)}\n",
      "Accuracy (GridSearchCV): 0.3445714285714286\n",
      "Classification Report (GridSearchCV):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.25      0.36      1132\n",
      "           1       0.59      0.37      0.45       621\n",
      "           2       0.42      0.06      0.11       519\n",
      "           3       0.28      0.01      0.02       946\n",
      "           4       0.47      0.03      0.06      1132\n",
      "           5       0.41      0.04      0.07       397\n",
      "           6       0.59      0.04      0.07       500\n",
      "           7       0.72      0.04      0.07       680\n",
      "           8       0.30      0.05      0.09       242\n",
      "           9       0.44      0.03      0.05       574\n",
      "          10       0.58      0.01      0.03       754\n",
      "          11       0.48      0.07      0.12       328\n",
      "          12       0.47      0.05      0.09       158\n",
      "          13       0.56      0.06      0.11       378\n",
      "          14       0.69      0.19      0.30       210\n",
      "          15       0.87      0.76      0.81       816\n",
      "          16       0.25      0.02      0.04        41\n",
      "          17       0.43      0.09      0.15       514\n",
      "          18       0.60      0.54      0.57       517\n",
      "          19       0.00      0.00      0.00       111\n",
      "          20       0.53      0.19      0.28       570\n",
      "          21       0.45      0.05      0.09        99\n",
      "          22       0.60      0.01      0.03       615\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.41      0.12      0.19       180\n",
      "          25       0.53      0.17      0.25       418\n",
      "          26       0.41      0.08      0.13       368\n",
      "\n",
      "   micro avg       0.62      0.15      0.25     12920\n",
      "   macro avg       0.47      0.12      0.17     12920\n",
      "weighted avg       0.53      0.15      0.20     12920\n",
      " samples avg       0.13      0.11      0.12     12920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', OneVsRestClassifier(LogisticRegression(max_iter=100)))\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],  # You can adjust the n-gram range\n",
    "    'vectorizer__max_features': [1000, 5000, 10000],  # You can adjust the max_features\n",
    "    'classifier__estimator__C': [0.1, 1, 10],  # Adjust regularization parameter for Logistic Regression\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(text_clf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Predictions using the best estimator\n",
    "y_pred_grid = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
    "classification_rep_grid = classification_report(y_test, y_pred_grid)\n",
    "\n",
    "print(f\"Accuracy (GridSearchCV): {accuracy_grid}\")\n",
    "print(\"Classification Report (GridSearchCV):\\n\", classification_rep_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3172857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.11      0.19      1132\n",
      "           1       0.54      0.16      0.25       621\n",
      "           2       0.42      0.11      0.18       519\n",
      "           3       0.26      0.03      0.05       946\n",
      "           4       0.16      0.03      0.05      1132\n",
      "           5       0.22      0.03      0.05       397\n",
      "           6       0.16      0.02      0.03       500\n",
      "           7       0.06      0.01      0.02       680\n",
      "           8       0.20      0.00      0.01       242\n",
      "           9       0.18      0.00      0.01       574\n",
      "          10       0.08      0.00      0.00       754\n",
      "          11       0.44      0.01      0.02       328\n",
      "          12       0.12      0.01      0.01       158\n",
      "          13       0.08      0.01      0.02       378\n",
      "          14       0.43      0.03      0.05       210\n",
      "          15       0.87      0.75      0.80       816\n",
      "          16       0.00      0.00      0.00        41\n",
      "          17       0.38      0.07      0.12       514\n",
      "          18       0.52      0.60      0.56       517\n",
      "          19       0.00      0.00      0.00       111\n",
      "          20       0.30      0.11      0.16       570\n",
      "          21       0.10      0.02      0.03        99\n",
      "          22       0.20      0.00      0.01       615\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.37      0.24      0.30       180\n",
      "          25       0.68      0.10      0.17       418\n",
      "          26       0.19      0.02      0.03       368\n",
      "\n",
      "   micro avg       0.49      0.12      0.19     12920\n",
      "   macro avg       0.28      0.09      0.12     12920\n",
      "weighted avg       0.33      0.12      0.15     12920\n",
      " samples avg       0.10      0.09      0.09     12920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with CountVectorizer and Random Forst\n",
    "text_clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', OneVsRestClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "text_clf.fit(X_train[:2000], y_train[:2000])\n",
    "\n",
    "# Predictions\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8306831242679411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_scores = roc_auc_score(y_test, grid_search.predict_proba(X_test), average='micro')\n",
    "print(f\"ROC AUC: {roc_auc_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "entry = \"Today has been a long day. A little tiring but full of surprises. I got my first acceptance today. I was on cloud nine!!! But I did not get place to sit in the train. but thats only a minor inconvienence. Im less stressed now.\"\n",
    "prediction = text_clf.predict([entry])\n",
    "\n",
    "print(\"Predicted labels:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
