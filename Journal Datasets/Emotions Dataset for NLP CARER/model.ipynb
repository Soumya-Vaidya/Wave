{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel rather rotten ambitious right</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update blog feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>never make separate ever want feel like ashamed</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave bouquet red yellow tulips arm feel sligh...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel little vain one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0                 feel rather rotten ambitious right  sadness\n",
       "1                            update blog feel shitty  sadness\n",
       "2    never make separate ever want feel like ashamed  sadness\n",
       "3  leave bouquet red yellow tulips arm feel sligh...      joy\n",
       "4                               feel little vain one  sadness"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data values and target values\n",
    "x = df['text']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (x,y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer to convert text into a numerical representation and removing stop words\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping vectorizer as Pickle\n",
    "\n",
    "with open('../../App/vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for all the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(15),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    SGDClassifier(),\n",
    "    MultinomialNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train_vectorized, y_train)\n",
    "#     pred=clf.predict(X_test_vectorized)\n",
    "#     print(clf, f1_score(y_test, pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier - 0.877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8727944614076785\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier()\n",
    "etc.fit(X_train_vectorized, y_train)\n",
    "y_pred = etc.predict(X_test_vectorized)\n",
    "accuracy = f1_score(y_test, y_pred,average='weighted')\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc = ExtraTreesClassifier(min_samples_split=5)\n",
    "# etc.fit(X_train_vectorized, y_train)\n",
    "# y_pred = etc.predict(X_test_vectorized)\n",
    "# accuracy = f1_score(y_test, y_pred,average='weighted')\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../App/model.pkl', 'wb') as file:\n",
    "    pickle.dump(etc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# etc = ExtraTreesClassifier()\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=etc, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# grid_search.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# best_etc = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = best_etc.predict(X_test_vectorized)\n",
    "\n",
    "# accuracy = f1_score(y_test, y_pred, average='weighted')\n",
    "# print(\"Best Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# etc = ExtraTreesClassifier()\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(50, 200),\n",
    "#     'max_depth': [None] + list(np.random.randint(1, 50, 10)),\n",
    "#     'min_samples_split': randint(2, 20),\n",
    "#     'min_samples_leaf': randint(1, 20),\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=etc, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1_weighted', random_state=42)\n",
    "\n",
    "# random_search.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# best_etc = random_search.best_estimator_\n",
    "\n",
    "# y_pred = best_etc.predict(X_test_vectorized)\n",
    "\n",
    "# accuracy = f1_score(y_test, y_pred, average='weighted')\n",
    "# print(\"Best Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: ['sadness']\n"
     ]
    }
   ],
   "source": [
    "new_text_entry = \"Im having a very good time!! but i think the overall experience is slightly tragic, dont you think?\"\n",
    "\n",
    "new_text_entry_vectorized = vectorizer.transform([new_text_entry])\n",
    "\n",
    "predicted_class = etc.predict(new_text_entry_vectorized)\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: ['love']\n"
     ]
    }
   ],
   "source": [
    "new_text_entry = \"Today has been a long day. A little tiring but full of surprises. I got my first acceptance today. I was on cloud nine!!! But I did not get place to sit in the train. but thats only a minor inconvienence. Im less stressed now.\"\n",
    "\n",
    "new_text_entry_vectorized = vectorizer.transform([new_text_entry])\n",
    "\n",
    "predicted_class = etc.predict(new_text_entry_vectorized)\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i just feel too overwhelmed i can t see the forest for the trees as the saying goes. sadness\n",
      "i am feeling pretty wonderful. joy\n",
      " anger\n",
      "anger: 1\n",
      "fear: 0\n",
      "sadness: 1\n",
      "love: 0\n",
      "joy: 1\n",
      "surprise: 0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"i am feeling pretty wonderful.\"\n",
    "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', input_text)\n",
    "\n",
    "# Create a dictionary to store emotion counts\n",
    "emotion_count = {'anger': 0, 'fear': 0, 'sadness': 0, 'love': 0, 'joy': 0 , 'surprise':0}  # Replace with actual emotion labels\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in sentences:\n",
    "    # Preprocess the sentence (optional, depending on your data)\n",
    "    # processed_sentence = preprocess_function(sentence)\n",
    "\n",
    "    # Transform the sentence\n",
    "    sentence_vectorized = vectorizer.transform([sentence])\n",
    "\n",
    "    # Predict emotion for the sentence\n",
    "    emotion_prediction = etc.predict(sentence_vectorized)[0]\n",
    "\n",
    "    # Update the emotion count\n",
    "    emotion_count[emotion_prediction] += 1\n",
    "    print(sentence, emotion_prediction)\n",
    "\n",
    "# Print the results\n",
    "for emotion, count in emotion_count.items():\n",
    "    print(f\"{emotion}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier - 0.872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8627248765439679\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_vectorized, y_train)\n",
    "y_pred = rfc.predict(X_test_vectorized)\n",
    "accuracy = f1_score(y_test, y_pred,average='weighted')\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869391076292237\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(min_samples_split=15)\n",
    "rfc.fit(X_train_vectorized, y_train)\n",
    "y_pred = rfc.predict(X_test_vectorized)\n",
    "accuracy = f1_score(y_test, y_pred,average='weighted')\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier - 0.8758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869284125810479\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train_vectorized, y_train)\n",
    "y_pred = sgd.predict(X_test_vectorized)\n",
    "accuracy = f1_score(y_test, y_pred,average='weighted')\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd_clf = SGDClassifier()\n",
    "\n",
    "# param_grid = {\n",
    "#     'loss': ['hinge', 'log', 'modified_huber'],\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#     'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "#     'max_iter': [1000, 2000, 3000],\n",
    "#     'tol': [1e-3, 1e-4, 1e-5]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=sgd_clf, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# grid_search.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# best_sgd_clf = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = best_sgd_clf.predict(X_test_vectorized)\n",
    "\n",
    "# accuracy = f1_score(y_test, y_pred, average='weighted')\n",
    "# print(\"Best Model Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
